{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the url\n",
    "html = urlopen(\"https://www.yourinvestmentpropertymag.com.au/top-suburbs/vic/\")\n",
    "bsobj = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsw', 'wa', 'act', 'vic', 'sa', 'tas', 'qld', 'nt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find suburb's href\n",
    "n=0\n",
    "suburb_href = []\n",
    "for l in bsobj.find_all('a', href=re.compile(\"^(/top-suburbs/)((?!:).)*$\")):\n",
    "    if 'href' in l.attrs:\n",
    "        n = n +1\n",
    "        suburb_href.append(l.attrs['href'])\n",
    "    if n == 9:\n",
    "        break\n",
    "suburb_href.pop(0)\n",
    "state =[]\n",
    "for states in suburb_href:\n",
    "    state.append(states.split('/')[-2])\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =['state',\n",
    " 'suburb',\n",
    " 'postcode',\n",
    " 'url',\n",
    " 'Median_price_house',\n",
    " 'Median_price_unit',\n",
    " 'Quarterly_growth_house',\n",
    " 'Quarterly_growth_unit'\n",
    " 'twelve_month_growth_house',\n",
    " 'twelve_month_growth_unit',\n",
    " 'Average_annual_growth_house',\n",
    " 'Average_annual_growth_unit',\n",
    " 'Weekly_median_rent_house',\n",
    " 'Weekly_median_rent_unit',\n",
    " 'Gross_rental_yield_house',\n",
    " 'Gross_rental_yield_unit',\n",
    " 'Number_of_Sales_(12m)_house',\n",
    " 'Number_of_Sales_(12m)_unit',\n",
    " 'Avg._Days_on_Market_(12m)_house',\n",
    " 'Avg._Days_on_Market_(12m)_unit',\n",
    " 'Total_population_2011',\n",
    " 'Total_population_2016',\n",
    " 'Population_change_(5y)_2011',\n",
    " 'Population_change_(5y)_2016',\n",
    " 'Median_household_income_(p/w)_2011',\n",
    " 'Median_household_income_(p/w)_2016',\n",
    " 'Household_income_change_(5y)_2011',\n",
    " 'Household_income_change_(5y)_2016',\n",
    " 'Median_age_of_persons_2011',\n",
    " 'Median_age_of_persons_2016',\n",
    " 'DESC_house',\n",
    " 'DESC_unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_link = 'https://www.yourinvestmentpropertymag.com.au'\n",
    "i= 0 \n",
    "\n",
    "for n in range(len(suburb_href)):\n",
    "    state_url = home_link + suburb_href[n]\n",
    "    response = requests.get(state_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    for href in soup.find_all('a', class_=\"visible-item\"):\n",
    "\n",
    "        if len(state[n]) == 3:\n",
    "            suburb_url = state_url + href['href'][17:]\n",
    "\n",
    "            df.loc[i,'state'] = state[n]\n",
    "            df.loc[i,'url'] = suburb_url\n",
    "            df.loc[i,'postcode'] = href['href'][17:].split('-')[0]\n",
    "            df.loc[i,'suburb'] = href['href'][17:].split('-',1)[1:][0].replace('-',' ')\n",
    "            suburb_response = requests.get(suburb_url)\n",
    "            suburb_soup = BeautifulSoup(suburb_response.content, 'html.parser')\n",
    "            c = 4\n",
    "            x = 19\n",
    "            for t in suburb_soup.find('div', {'class' : 'key-market-data'}).find_all('span'):\n",
    "                data = t.text.replace(\"$\",\"\")\n",
    "                data = data.replace(\",\",\"\")\n",
    "                data = data.replace(\"+\",\"\")\n",
    "                if data == '–':\n",
    "                    data = 'Null'\n",
    "                df.loc[i,labels[c]] = data\n",
    "                c= c+1\n",
    "            for t in suburb_soup.find('div', {'class' : 'key-demographics'}).find_all('span'):\n",
    "                data = t.text.replace(\"$\",\"\")\n",
    "                data = data.replace(\",\",\"\")\n",
    "                data = data.replace(\"+\",\"\")\n",
    "                if data == '–':\n",
    "                    data = 'Null'\n",
    "                df.loc[i,labels[x]] = data\n",
    "                x= x+1\n",
    "        else:\n",
    "            suburb_url = state_url + href['href'][16:]\n",
    "            df.loc[i,'state'] = state[n]\n",
    "            df.loc[i,'url'] = suburb_url\n",
    "            df.loc[i,'postcode'] = href['href'][16:].split('-')[0]\n",
    "            df.loc[i,'suburb'] = href['href'][16:].split('-',1)[1:][0].replace('-',' ')\n",
    "            suburb_response = requests.get(suburb_url)\n",
    "            suburb_soup = BeautifulSoup(suburb_response.content, 'html.parser')\n",
    "            c = 4\n",
    "            x = 19\n",
    "            for t in suburb_soup.find('div', {'class' : 'key-market-data'}).find_all('span'):\n",
    "                data = t.text.replace(\"$\",\"\")\n",
    "                data = data.replace(\",\",\"\")\n",
    "                data = data.replace(\"+\",\"\")\n",
    "                if data == '–':\n",
    "                    data = 'Null'\n",
    "                df.loc[i,labels[c]] = data\n",
    "                c= c+1\n",
    "            for t in suburb_soup.find('div', {'class' : 'key-demographics'}).find_all('span'):\n",
    "                data = t.text.replace(\"$\",\"\")\n",
    "                data = data.replace(\",\",\"\")\n",
    "                data = data.replace(\"+\",\"\")\n",
    "                if data == '–':\n",
    "                    data = 'Null'\n",
    "                df.loc[i,labels[x]] = data\n",
    "                x= x+1\n",
    "\n",
    "\n",
    "        i = i +1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    suburb_url = df['url'][i]\n",
    "    suburb_response = requests.get(suburb_url)\n",
    "    suburb_desc_soup = BeautifulSoup(suburb_response.content, 'html.parser')\n",
    "    DESC_house = suburb_desc_soup.find('div', {'aria-labelledby' :'pills-house-report-tab'}).text.replace('\\n','')\n",
    "    df.loc[i,'DESC_house'] = DESC_house\n",
    "    DESC_unit = suburb_desc_soup.find('div', {'id' :'pills-unit-report'}).text.replace('\\n','')\n",
    "    df.loc[i,'DESC_unit'] = DESC_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('suburb.csv')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
